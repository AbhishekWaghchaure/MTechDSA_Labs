{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Database for binary classification\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = datasets.make_blobs(n_samples=150,n_features=2,\n",
    "                           centers=2,cluster_std=1.05,\n",
    "                           random_state=2)\n",
    "#Plotting\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], 'r^')\n",
    "plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], 'bs')\n",
    "plt.xlabel(\"feature 1\")\n",
    "plt.ylabel(\"feature 2\")\n",
    "plt.title('Random Classification Data with 2 classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step Function\n",
    "\n",
    "def step_func(z):\n",
    "        return 1.0 if (z > 0) else 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perceptron(X, y, lr, epochs):\n",
    "\n",
    "    # X --> Inputs.\n",
    "    # y --> labels/target.\n",
    "    # lr --> learning rate.\n",
    "    # epochs --> Number of iterations.\n",
    "\n",
    "    # m-> number of training examples\n",
    "    # n-> number of features\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initializing parapeters(theta) to zeros.\n",
    "    # +1 in n+1 for the bias term.\n",
    "    theta = np.zeros((n+1,1))\n",
    "\n",
    "    # Empty list to store how many examples were\n",
    "    # misclassified at every iteration.\n",
    "    n_miss_list = []\n",
    "\n",
    "    # Training.\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # variable to store #misclassified.\n",
    "        n_miss = 0\n",
    "\n",
    "        # looping for every example.\n",
    "        for idx, x_i in enumerate(X):\n",
    "\n",
    "            # Insering 1 for bias, X0 = 1.\n",
    "            x_i = np.insert(x_i, 0, 1).reshape(-1,1)\n",
    "\n",
    "            # Calculating prediction/hypothesis.\n",
    "            y_hat = step_func(np.dot(x_i.T, theta))\n",
    "\n",
    "            # Updating if the example is misclassified.\n",
    "            if (np.squeeze(y_hat) - y[idx]) != 0:\n",
    "                theta += lr*((y[idx] - y_hat)*x_i)\n",
    "\n",
    "                # Incrementing by 1.\n",
    "                n_miss += 1\n",
    "\n",
    "        # Appending number of misclassified examples\n",
    "        # at every iteration.\n",
    "        n_miss_list.append(n_miss)\n",
    "\n",
    "    return theta, n_miss_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, theta):\n",
    "    # X --> Inputs\n",
    "    # theta --> parameters\n",
    "\n",
    "    # The Line is y=mx+c\n",
    "    # So, Equate mx+c = theta0.X0 + theta1.X1 + theta2.X2\n",
    "    # Solving we find m and c\n",
    "    x1 = [min(X[:, 0]), max(X[:, 0])]\n",
    "    m = -theta[1] / theta[2]\n",
    "    c = -theta[0] / theta[2]\n",
    "    x2 = m * x1 + c\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], \"r^\")\n",
    "    plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], \"bs\")\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.title('Perceptron Algorithm')\n",
    "    plt.plot(x1, x2, 'y-')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theta, miss_l = perceptron(X, y, 0.5, 100)\n",
    "plot_decision_boundary(X, theta)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
